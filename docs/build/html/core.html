

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lagom.core &mdash; lagom 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="lagom.engine" href="engine.html" />
    <link rel="prev" title="lagom.contrib" href="contrib.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> lagom
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installing lagom</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples_vae.html">Variational Auto-Encoder (VAE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_mdn.html">Mixture Density Network (MDN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_es.html">Evolution Strategies (ES)</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_pg.html">Policy Gradient</a></li>
</ul>
<p class="caption"><span class="caption-text">lagom API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lagom.html">lagom</a></li>
<li class="toctree-l1"><a class="reference internal" href="agents.html">lagom.agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib.html">lagom.contrib</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">lagom.core</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#evolution-strategies-es">Evolution Strategies (ES)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#es-infrastructure">ES infrastructure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#es-algorithms">ES algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#test-functions">Test functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multiprocessing">Multiprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#networks">Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plotter">Plotter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#policies">Policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="#transformations">Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="engine.html">lagom.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="envs.html">lagom.envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="experiment.html">lagom.experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="runner.html">lagom.runner</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">lagom</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>lagom.core</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/core.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-lagom.core">
<span id="lagom-core"></span><h1>lagom.core<a class="headerlink" href="#module-lagom.core" title="Permalink to this headline">¶</a></h1>
<div class="section" id="evolution-strategies-es">
<h2>Evolution Strategies (ES)<a class="headerlink" href="#evolution-strategies-es" title="Permalink to this headline">¶</a></h2>
<div class="section" id="es-infrastructure">
<h3>ES infrastructure<a class="headerlink" href="#es-infrastructure" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="lagom.core.es.BaseES">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">BaseES</code><a class="reference internal" href="_modules/lagom/core/es/base_es.html#BaseES"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseES" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for evolution strategies.</p>
<p>Note that the optimization should be treated as minimization.</p>
<p>All inherited subclasses should at least implement the following functions:
1. ask(self)
2. tell(self, solutions, function_values)
3. &#64;property: result(self)</p>
<dl class="method">
<dt id="lagom.core.es.BaseES.ask">
<code class="descname">ask</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es.html#BaseES.ask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseES.ask" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample new candidate solutions.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd>solutions (list/ndarray): sampled candidate solutions</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.es.BaseES.result">
<code class="descname">result</code><a class="headerlink" href="#lagom.core.es.BaseES.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return all necessary results after the optimization.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>results (dict): a dictionary of results. </dt>
<dd>e.g. [‘best_param’, ‘best_f_val’, ‘hist_best_param’, ‘stds’]</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.es.BaseES.tell">
<code class="descname">tell</code><span class="sig-paren">(</span><em>solutions</em>, <em>function_values</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es.html#BaseES.tell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseES.tell" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the values of objective function evaluated for sampled solutions to prepare for next iteration.
i.e. update the parameters of the population.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>solutions (list/ndarray): candidate solutions sampled from ask()
function_values (list): objective function values evaluated for sampled solutions</dd>
</dl>
<p>Returns:</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.es.BaseESMaster">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">BaseESMaster</code><span class="sig-paren">(</span><em>num_iteration</em>, <em>worker_class</em>, <em>num_worker</em>, <em>init_seed=0</em>, <em>daemonic_worker=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es_master.html#BaseESMaster"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseESMaster" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for master of parallelized evolution strategies (ES).</p>
<p>It internally defines an ES algorithm. 
In each generation, it distributes all sampled solution candidates, each for one worker,
to compute a list of object function values and then update the ES.</p>
<p>For more details about how master class works, please refer
to the documentation of the class, BaseIterativeMaster.</p>
<p>All inherited subclasses should at least implement the following function:
1. make_es(self)
2. _process_es_result(self, result)</p>
<dl class="method">
<dt id="lagom.core.es.BaseESMaster.make_es">
<code class="descname">make_es</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es_master.html#BaseESMaster.make_es"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseESMaster.make_es" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create an ES algorithm.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd>es (BaseES): An instantiated object of an ES class.</dd>
<dt>Examples:</dt>
<dd><dl class="first docutils">
<dt>cmaes = CMAES(mu0=[3]*100, </dt>
<dd>std0=0.5, 
popsize=12)</dd>
</dl>
<p class="last">return cmaes</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.es.BaseESMaster.make_tasks">
<code class="descname">make_tasks</code><span class="sig-paren">(</span><em>iteration</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es_master.html#BaseESMaster.make_tasks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseESMaster.make_tasks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a set of iteration-dependent tasks.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>iteration (int): the iteration index</dd>
<dt>Returns:</dt>
<dd>tasks (list): a list of tasks</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.es.BaseESWorker">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">BaseESWorker</code><a class="reference internal" href="_modules/lagom/core/es/base_es_worker.html#BaseESWorker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseESWorker" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for the worker of parallelized evolution strategies (ES).</p>
<p>It defines an objective function to evaluate the given solution 
candidate and compute a objective function value.</p>
<p>For more details about how worker class works, please refer
to the documentation of the class, BaseWorker.</p>
<p>All inherited subclasses should at least implement the following function:
1. f(self, solution, seed)</p>
<dl class="method">
<dt id="lagom.core.es.BaseESWorker.f">
<code class="descname">f</code><span class="sig-paren">(</span><em>solution</em>, <em>seed</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es_worker.html#BaseESWorker.f"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseESWorker.f" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to define the objective function given
the solution candidate.</p>
<p>Note that the solution argument can contain additional information 
needed for evaluating the objective function value. For example, 
if the usecase is doing RL with gym environments, then solution
could contain a function to create an environment. 
e.g. <cite>solution, make_env = solution</cite></p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">solution (object): given solution candidate. 
seed (int): random seed contained in master_cmd.</p>
<blockquote class="last">
<div>It can be used to seed the current evaluation, e.g. gym environment.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd>function_value (float): objective function value</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.es.BaseESWorker.work">
<code class="descname">work</code><span class="sig-paren">(</span><em>master_cmd</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_es_worker.html#BaseESWorker.work"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseESWorker.work" title="Permalink to this definition">¶</a></dt>
<dd><p>Define how to do the work given the master’s command and returns the working result.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>master_cmd (list): master’s command. [task_id, task, seed]</dd>
<dt>Returns:</dt>
<dd>task_id (int): task ID
result (object): working result</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.es.BaseGymESMaster">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">BaseGymESMaster</code><span class="sig-paren">(</span><em>make_env</em>, <em>num_iteration</em>, <em>worker_class</em>, <em>num_worker</em>, <em>init_seed=0</em>, <em>daemonic_worker=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_gym_es_master.html#BaseGymESMaster"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseGymESMaster" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for master of evolution strategies with OpenAI gym environment.</p>
<p>It is similar to the class, BaseESMaster, the major difference is that
this class receives a <cite>make_env()</cite> function and pack it with each task
sending to the workers. Each worker can use it to create an environment.</p>
<p>For more details about how master class works, please refer
to the documentation of the class, BaseIterativeMaster.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_es(self)
2. _process_es_result(self, result)</p>
<dl class="method">
<dt id="lagom.core.es.BaseGymESMaster.make_tasks">
<code class="descname">make_tasks</code><span class="sig-paren">(</span><em>iteration</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/base_gym_es_master.html#BaseGymESMaster.make_tasks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.BaseGymESMaster.make_tasks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a set of iteration-dependent tasks.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>iteration (int): the iteration index</dd>
<dt>Returns:</dt>
<dd>tasks (list): a list of tasks</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.es.ESOptimizer">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">ESOptimizer</code><span class="sig-paren">(</span><em>es</em>, <em>f</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/es_optimizer.html#ESOptimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.ESOptimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimizer for evolution strategies (ES).</p>
<p>Each step it samples a solution set and evaluate</p>
<p>Note that this implementation is naive step-by-step version. For parallelized ES, please 
refer to classes BaseESWorker and BaseESMaster.</p>
<dl class="method">
<dt id="lagom.core.es.ESOptimizer.step">
<code class="descname">step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/es_optimizer.html#ESOptimizer.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.ESOptimizer.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform one iteration (generation) of evolution strategy</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="es-algorithms">
<h3>ES algorithms<a class="headerlink" href="#es-algorithms" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="lagom.core.es.CMAES">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">CMAES</code><span class="sig-paren">(</span><em>mu0</em>, <em>std0</em>, <em>popsize</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/cma_es.html#CMAES"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.CMAES" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper of original CMA-ES implementation at <a class="reference external" href="https://github.com/CMA-ES/pycma">https://github.com/CMA-ES/pycma</a></p>
<p>Note that we minimize the objective, i.e. function values in tell().</p>
<dl class="method">
<dt id="lagom.core.es.CMAES.ask">
<code class="descname">ask</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/cma_es.html#CMAES.ask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.CMAES.ask" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample new candidate solutions.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd>solutions (list/ndarray): sampled candidate solutions</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.es.CMAES.result">
<code class="descname">result</code><a class="headerlink" href="#lagom.core.es.CMAES.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return all necessary results after the optimization.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>results (dict): a dictionary of results. </dt>
<dd>e.g. [‘best_param’, ‘best_f_val’, ‘hist_best_param’, ‘stds’]</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.es.CMAES.tell">
<code class="descname">tell</code><span class="sig-paren">(</span><em>solutions</em>, <em>function_values</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/cma_es.html#CMAES.tell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.CMAES.tell" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the values of objective function evaluated for sampled solutions to prepare for next iteration.
i.e. update the parameters of the population.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>solutions (list/ndarray): candidate solutions sampled from ask()
function_values (list): objective function values evaluated for sampled solutions</dd>
</dl>
<p>Returns:</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.es.OpenAIES">
<em class="property">class </em><code class="descclassname">lagom.core.es.</code><code class="descname">OpenAIES</code><span class="sig-paren">(</span><em>mu0</em>, <em>std0</em>, <em>popsize</em>, <em>std_decay=0.999</em>, <em>min_std=0.01</em>, <em>lr=0.001</em>, <em>lr_decay=0.9999</em>, <em>min_lr=0.01</em>, <em>antithetic=False</em>, <em>rank_transform=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/openai_es.html#OpenAIES"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.OpenAIES" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple version of OpenAI evolution strategies.</p>
<p>Note that we minimize the objective, i.e. function values in tell().</p>
<p>A practical tip, the learning rate is better to be proportional to batch size
i.e. larger batch size, use larger learning rate and vise versa.</p>
<dl class="method">
<dt id="lagom.core.es.OpenAIES.ask">
<code class="descname">ask</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/openai_es.html#OpenAIES.ask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.OpenAIES.ask" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample new candidate solutions.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd>solutions (list/ndarray): sampled candidate solutions</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.es.OpenAIES.result">
<code class="descname">result</code><a class="headerlink" href="#lagom.core.es.OpenAIES.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return all necessary results after the optimization.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>results (dict): a dictionary of results. </dt>
<dd>e.g. [‘best_param’, ‘best_f_val’, ‘hist_best_param’, ‘stds’]</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.es.OpenAIES.tell">
<code class="descname">tell</code><span class="sig-paren">(</span><em>solutions</em>, <em>function_values</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/openai_es.html#OpenAIES.tell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.OpenAIES.tell" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the values of objective function evaluated for sampled solutions to prepare for next iteration.
i.e. update the parameters of the population.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>solutions (list/ndarray): candidate solutions sampled from ask()
function_values (list): objective function values evaluated for sampled solutions</dd>
</dl>
<p>Returns:</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="test-functions">
<h3>Test functions<a class="headerlink" href="#test-functions" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="lagom.core.es.test_functions.BaseTestFunction">
<em class="property">class </em><code class="descclassname">lagom.core.es.test_functions.</code><code class="descname">BaseTestFunction</code><a class="reference internal" href="_modules/lagom/core/es/test_functions/base_test_function.html#BaseTestFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.test_functions.BaseTestFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for test function in optimization.
For more details, please refer to
<a class="reference external" href="https://en.wikipedia.org/wiki/Test_functions_for_optimization">https://en.wikipedia.org/wiki/Test_functions_for_optimization</a></p>
<p>All inherited subclasses should at least implement the following functions:
1. __call__(self, x)</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.es.test_functions.Rastrigin">
<em class="property">class </em><code class="descclassname">lagom.core.es.test_functions.</code><code class="descname">Rastrigin</code><a class="reference internal" href="_modules/lagom/core/es/test_functions/rastrigin.html#Rastrigin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.test_functions.Rastrigin" title="Permalink to this definition">¶</a></dt>
<dd><p>Rastrigin test objective function for optimization
<a class="reference external" href="https://en.wikipedia.org/wiki/Test_functions_for_optimization">https://en.wikipedia.org/wiki/Test_functions_for_optimization</a></p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.es.test_functions.Sphere">
<em class="property">class </em><code class="descclassname">lagom.core.es.test_functions.</code><code class="descname">Sphere</code><span class="sig-paren">(</span><em>min=-1000</em>, <em>max=1000</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/es/test_functions/sphere.html#Sphere"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.test_functions.Sphere" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="lagom.core.es.test_functions.HolderTable">
<em class="property">class </em><code class="descclassname">lagom.core.es.test_functions.</code><code class="descname">HolderTable</code><a class="reference internal" href="_modules/lagom/core/es/test_functions/holder_table.html#HolderTable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.test_functions.HolderTable" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="lagom.core.es.test_functions.StyblinskiTang">
<em class="property">class </em><code class="descclassname">lagom.core.es.test_functions.</code><code class="descname">StyblinskiTang</code><a class="reference internal" href="_modules/lagom/core/es/test_functions/styblinski_tang.html#StyblinskiTang"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.es.test_functions.StyblinskiTang" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>
<div class="section" id="multiprocessing">
<h2>Multiprocessing<a class="headerlink" href="#multiprocessing" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lagom.core.multiprocessing.BaseMaster">
<em class="property">class </em><code class="descclassname">lagom.core.multiprocessing.</code><code class="descname">BaseMaster</code><span class="sig-paren">(</span><em>worker_class</em>, <em>num_worker</em>, <em>init_seed=0</em>, <em>daemonic_worker=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_master.html#BaseMaster"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseMaster" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class of a callable master to parallelize solving a set of tasks, each with a worker.</p>
<p>Each calling it initialize all the workers (each opens a Process) and independent Pipe connections
between each worker and itself. And then it makes a set of tasks and assign each task to a worker.
After processing each working results received from workers, it stops all workers and terminate
all processes.</p>
<p>Note that it is possible to make less tasks than the number of workers, however, it is not generally
recommended to do so.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_tasks(self)
2. _process_workers_result(self, tasks, workers_result)</p>
<dl class="method">
<dt id="lagom.core.multiprocessing.BaseMaster.assign_tasks">
<code class="descname">assign_tasks</code><span class="sig-paren">(</span><em>tasks</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_master.html#BaseMaster.assign_tasks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseMaster.assign_tasks" title="Permalink to this definition">¶</a></dt>
<dd><p>Assign each task to a worker. And process the results from all tasks.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>tasks (list): a list of tasks</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.multiprocessing.BaseMaster.initialize_workers">
<code class="descname">initialize_workers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_master.html#BaseMaster.initialize_workers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseMaster.initialize_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize all workers, each opens a Process. 
Create an independent Pipe connection between master and each worker.</p>
</dd></dl>

<dl class="method">
<dt id="lagom.core.multiprocessing.BaseMaster.make_tasks">
<code class="descname">make_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_master.html#BaseMaster.make_tasks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseMaster.make_tasks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a set of tasks.</p>
<dl class="docutils">
<dt>Returns:</dt>
<dd>tasks (list): a list of tasks</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.multiprocessing.BaseMaster.stop_workers">
<code class="descname">stop_workers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_master.html#BaseMaster.stop_workers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseMaster.stop_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>Stop all the workers by sending a ‘close’ signal via pipe connection and join all processes.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.multiprocessing.BaseWorker">
<em class="property">class </em><code class="descclassname">lagom.core.multiprocessing.</code><code class="descname">BaseWorker</code><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_worker.html#BaseWorker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseWorker" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class of a callable worker to work on a task assigned by the master.</p>
<p>Each calling it stands by with a infinite while loop, waiting for master’s command to work
and it receives Pipe connection ends between master and itself.</p>
<p>When it receives a ‘close’ command from master, it close the worker connection and break the loop.</p>
<p>Note that it is a good practice to close the master connection although it is not used
because the forked process for the worker will anyway copy both connection ends.</p>
<p>All inherited subclasses should at least implement the following functions:
1. work(self, master_cmd)</p>
<dl class="docutils">
<dt>Remark: To be optimally user-friendly, it is highly recommended not to override constructor __init__</dt>
<dd>All additional settings for the worker should be sent directly through <cite>master_cmd</cite>. 
Thus each time the master can create a worker with a Process without passing arguments to constructor.</dd>
</dl>
<dl class="method">
<dt id="lagom.core.multiprocessing.BaseWorker.work">
<code class="descname">work</code><span class="sig-paren">(</span><em>master_cmd</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_worker.html#BaseWorker.work"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseWorker.work" title="Permalink to this definition">¶</a></dt>
<dd><p>Define how to do the work given the master’s command and returns the working result.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>master_cmd (list): master’s command. [task_id, task, seed]</dd>
<dt>Returns:</dt>
<dd>task_id (int): task ID
result (object): working result</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.multiprocessing.BaseIterativeMaster">
<em class="property">class </em><code class="descclassname">lagom.core.multiprocessing.</code><code class="descname">BaseIterativeMaster</code><span class="sig-paren">(</span><em>num_iteration</em>, <em>worker_class</em>, <em>num_worker</em>, <em>init_seed=0</em>, <em>daemonic_worker=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_iterative_master.html#BaseIterativeMaster"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseIterativeMaster" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for iterative version of a callable master. 
It supports iterative procedure during each call as following</p>
<p># Initialize all workers
self.initialize_workers()</p>
<p># Iteratively make and assign tasks
for iteration in range(num_iterations):</p>
<blockquote>
<div>self.make_tasks(iteration)
self.assign_tasks()</div></blockquote>
<p># Stop all workers and terminate all processes
self.stop_workers()</p>
<p>All inherited subclasses should at least implement the following function
1. make_tasks(self, iteration)
2. _process_workers_result(self, tasks, workers_result)</p>
<dl class="method">
<dt id="lagom.core.multiprocessing.BaseIterativeMaster.make_tasks">
<code class="descname">make_tasks</code><span class="sig-paren">(</span><em>iteration</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/multiprocessing/base_iterative_master.html#BaseIterativeMaster.make_tasks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.multiprocessing.BaseIterativeMaster.make_tasks" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a set of iteration-dependent tasks.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>iteration (int): the iteration index</dd>
<dt>Returns:</dt>
<dd>tasks (list): a list of tasks</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="networks">
<h2>Networks<a class="headerlink" href="#networks" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lagom.core.networks.BaseNetwork">
<em class="property">class </em><code class="descclassname">lagom.core.networks.</code><code class="descname">BaseNetwork</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for neural networks.</p>
<p>Depending on the type of neural networks (e.g. policy network, Q-network), it is recommended
to override the constructor __init__ to provide essential items for the neural network.</p>
<p>Note that if subclass overrides __init__, remember to provide
keywords aguments, i.e. <a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs passing to super().__init__.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_params(self, config)
2. init_params(self, config)</p>
<dl class="method">
<dt id="lagom.core.networks.BaseNetwork.from_vec">
<code class="descname">from_vec</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork.from_vec"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork.from_vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Unflatten the given vector as the network parameters.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (Tensor): flattened single vector with size consistent of the number of network paramters.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseNetwork.init_params">
<code class="descname">init_params</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork.init_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork.init_params" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to initialize all created parameters</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseNetwork.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>f</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the model parameters. It is loaded by using recommended way from PyTorch documentation. 
<a class="reference external" href="https://pytorch.org/docs/master/notes/serialization.html#best-practices">https://pytorch.org/docs/master/notes/serialization.html#best-practices</a></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>f (str): loading path</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseNetwork.make_params">
<code class="descname">make_params</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork.make_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork.make_params" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all trainable parameters (layers)</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Examples:</dt>
<dd>Refer to each inherited subclass with individual documentation.</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.networks.BaseNetwork.num_params">
<code class="descname">num_params</code><a class="headerlink" href="#lagom.core.networks.BaseNetwork.num_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of trainable parameters.</p>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseNetwork.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>f</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the model parameters. It is saved by using recommended way from PyTorch documentation. 
<a class="reference external" href="https://pytorch.org/docs/master/notes/serialization.html#best-practices">https://pytorch.org/docs/master/notes/serialization.html#best-practices</a></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>f (str): saving path</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseNetwork.to_vec">
<code class="descname">to_vec</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_network.html#BaseNetwork.to_vec"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseNetwork.to_vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Flatten the network parameters into a single big vector.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.networks.BaseMLP">
<em class="property">class </em><code class="descclassname">lagom.core.networks.</code><code class="descname">BaseMLP</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mlp.html#BaseMLP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for fully connected neural network (or Multi-Layer Perceptron)</p>
<p>Note that if subclass overrides __init__, remember to provide
keywords aguments, i.e. <a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs passing to super().__init__.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_params(self, config)
2. init_params(self, config)
3. forward(self, x)</p>
<p>Examples:</p>
<dl class="docutils">
<dt>class MLP(BaseMLP):</dt>
<dd><dl class="first last docutils">
<dt>def make_params(self, config):</dt>
<dd>self.fc1 = nn.Linear(in_features=5, out_features=32)
self.fc2 = nn.Linear(in_features=32, out_features=10)</dd>
<dt>def init_params(self, config):</dt>
<dd><p class="first">gain = nn.init.calculate_gain(nonlinearity=’relu’)</p>
<p>nn.init.orthogonal_(self.fc1.weight, gain=gain)
nn.init.constant_(self.fc1.bias, 0.0)</p>
<p class="last">nn.init.orthogonal_(self.fc2.weight, gain=gain)
nn.init.constant_(self.fc2.bias, 0.0)</p>
</dd>
<dt>def forward(self, x):</dt>
<dd><p class="first">x = F.relu(self.fc1(x))
x = self.fc2(x)</p>
<p class="last">return x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="lagom.core.networks.BaseCNN">
<em class="property">class </em><code class="descclassname">lagom.core.networks.</code><code class="descname">BaseCNN</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_cnn.html#BaseCNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseCNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for convolutional neural networks.</p>
<p>Note that if subclass overrides __init__, remember to provide
keywords aguments, i.e. <a href="#id5"><span class="problematic" id="id6">**</span></a>kwargs passing to super().__init__.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_params(self, config)
2. init_params(self, config)
3. forward(self, x)</p>
<p>Examples:</p>
<dl class="docutils">
<dt>class CNN(BaseCNN):</dt>
<dd><dl class="first last docutils">
<dt>def make_params(self, config):</dt>
<dd>self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)
self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3)
self.fc1 = nn.Linear(in_features=4608, out_features=1)</dd>
<dt>def init_params(self, config):</dt>
<dd><p class="first">gain = nn.init.calculate_gain(‘relu’)</p>
<p>nn.init.orthogonal_(self.conv1.weight, gain=gain)
nn.init.constant_(self.conv1.bias, 0.0)</p>
<p>nn.init.orthogonal_(self.conv2.weight, gain=gain)
nn.init.constant_(self.conv2.bias, 0.0)</p>
<p class="last">nn.init.orthogonal_(self.fc1.weight, gain=gain)
nn.init.constant_(self.fc1.bias, 0.0)</p>
</dd>
<dt>def forward(self, x):</dt>
<dd><p class="first">x = F.relu(self.conv1(x))
x = F.relu(self.conv2(x))
x = x.view(x.shape[0], -1)
print(x.shape)
x = self.fc1(x)</p>
<p class="last">return x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="lagom.core.networks.BaseMDN">
<em class="property">class </em><code class="descclassname">lagom.core.networks.</code><code class="descname">BaseMDN</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for mixture density networks (we use Gaussian mixture).</p>
<p>This class defines the mixture density networks using isotropic Gaussian densities.</p>
<p>The network receives input tensor and outputs parameters for a mixture of Gaussian distributions. 
i.e. mixing coefficients, means and variances.</p>
<p>Specifically, their dimensions are following, given N is batch size, K is the number of densities
and D is the data dimension</p>
<ul class="simple">
<li>mixing coefficients: [N, K, D]</li>
<li>mean: [N, K, D]</li>
<li>variance: [N, K, D]</li>
</ul>
<p>Note that if subclass overrides __init__, remember to provide
keywords aguments, i.e. <a href="#id7"><span class="problematic" id="id8">**</span></a>kwargs passing to super().__init__.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_feature_layers(self, config)
2. make_mdn_heads(self, config)
3. init_params(self, config)
4. feature_forward(self, x)</p>
<p>Examples:</p>
<dl class="docutils">
<dt>class MDN(BaseMDN):</dt>
<dd><dl class="first last docutils">
<dt>def make_feature_layers(self, config):</dt>
<dd><p class="first">fc1 = nn.Linear(in_features=1, out_features=15)
fc2 = nn.Linear(in_features=15, out_features=15)</p>
<p>feature_layers = nn.ModuleList([fc1, fc2])</p>
<p class="last">return feature_layers</p>
</dd>
<dt>def make_mdn_heads(self, config):</dt>
<dd><p class="first">unnormalized_pi_head = nn.Linear(in_features=15, out_features=20*1)
mu_head = nn.Linear(in_features=15, out_features=20*1)
logvar_head = nn.Linear(in_features=15, out_features=20*1)</p>
<p>num_densities = 20
data_dim = 1</p>
<p class="last">return unnormalized_pi_head, mu_head, logvar_head, num_densities, data_dim</p>
</dd>
<dt>def init_params(self, config):</dt>
<dd><dl class="first docutils">
<dt>for module in self.feature_layers:</dt>
<dd><p class="first">gain = nn.init.calculate_gain(‘tanh’)</p>
<p class="last">nn.init.orthogonal_(module.weight, gain=gain)
nn.init.constant_(module.bias, 0.0)</p>
</dd>
</dl>
<p>nn.init.orthogonal_(self.unnormalized_pi_head.weight, gain=gain)
nn.init.constant_(self.unnormalized_pi_head.bias, 0.0)</p>
<p>nn.init.orthogonal_(self.mu_head.weight, gain=gain)
nn.init.constant_(self.mu_head.bias, 0.0)</p>
<p class="last">nn.init.orthogonal_(self.logvar_head.weight, gain=gain)
nn.init.constant_(self.logvar_head.bias, 0.0)</p>
</dd>
<dt>def feature_forward(self, x):</dt>
<dd><dl class="first docutils">
<dt>for module in self.feature_layers:</dt>
<dd>x = torch.tanh(module(x))</dd>
</dl>
<p class="last">return x</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="lagom.core.networks.BaseMDN.MDN_loss">
<code class="descname">MDN_loss</code><span class="sig-paren">(</span><em>log_pi</em>, <em>mu</em>, <em>std</em>, <em>target</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.MDN_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.MDN_loss" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Calculate the loss function</p>
<p>i.e. negative log-likelihood of the target given the parameters of Gaussian mixtures
L = -</p>
</div></blockquote>
<dl class="docutils">
<dt>rac{1}{N}sum_{n=1}^{N}(ln(sum_{k=1}^{K} pi_k*Gaussian probability))</dt>
<dd>For better numerical stability, we could use log-scale of denstiy mixture 
L = -</dd>
</dl>
<p>rac{1}{N}sum_{n=1}^{N}(ln(sum_{k=1}^{K} exp( log pi_k + log Gaussian probability)) )</p>
<blockquote>
<div><p>Note that simply computing this loss function is numerically unstable.
Due to the fact that the density mixture might be very small value, resulting in +/- Inf.
To address this problem, we use log-sum-exp trick</p>
<p>i.e. logsum_{i=1}^{N}exp(x_i) = a + logsum_{i=1}^{N}exp(x_i - a), where a = max_i(x_i)</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>log_pi (Tensor): log-scale mixing coefficients, shape [N, K, D]
mu (Tensor): mean of Gaussian mixtures, shape [N, K, D]
std (Tensor): standard deviation of Gaussian mixtures, shape [N, K, D]
target (Tensor): target tensor, shape [N, D]</dd>
<dt>Returns:</dt>
<dd>loss (Tensor): calculated loss</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseMDN.feature_forward">
<code class="descname">feature_forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.feature_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.feature_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to define forward pass of feature layers, before MDN heads.</p>
<p>It should use the class member, self.feature_layers, 
which is a ModuleList consisting of all defined parameters (layers).</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (Tensor): input tensor</dd>
<dt>Returns:</dt>
<dd>x (Tensor): feature tensor before the MDN heads.</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseMDN.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseMDN.make_feature_layers">
<code class="descname">make_feature_layers</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.make_feature_layers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.make_feature_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create the parameters for all the feature layers.</p>
<p>Note that it must return a ModuleList, otherwise they cannot be tracked by PyTorch.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Returns:</dt>
<dd>feature_layers (nn.ModuleList): ModuleList of feature layers</dd>
<dt>Examples:</dt>
<dd>TODO:</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseMDN.make_mdn_heads">
<code class="descname">make_mdn_heads</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.make_mdn_heads"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.make_mdn_heads" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all the parameters (layers) for heads of
unnormalized pi (mixing coefficient), mu and logvar. Note that they should
output dimensions, K*D, where K is the number of densities and D is 
the data dimensions.</p>
<p>Note that it must return a ModuleList, otherwise they cannot be tracked by PyTorch.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Returns:</dt>
<dd>unnormalized_pi_head (nn.Module): A module for un-normalized pi (mixing coefficients). 
mu_head (nn.Module): A module for mean head. 
logvar_head (nn.Module): A module for log-variance head. 
num_densities (int): number of densities
data_dim (int): data dimension</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseMDN.make_params">
<code class="descname">make_params</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.make_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.make_params" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all trainable parameters (layers)</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Examples:</dt>
<dd>Refer to each inherited subclass with individual documentation.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseMDN.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>log_pi</em>, <em>mu</em>, <em>std</em>, <em>tau=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_mdn.html#BaseMDN.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseMDN.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sampling from Gaussian mixture using reparameterization trick.</p>
<ul class="simple">
<li>Firstly sample categorically from mixing coefficients to determine a Gaussian distribution</li>
<li>Then sample from selected Gaussian distribution</li>
</ul>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">log_pi (Tensor): log-scale mixing coefficients, shape [N, K, D]
mu (Tensor): mean of Gaussian mixtures, shape [N, K, D]
std (Tensor): standard deviation of Gaussian mixtures, shape [N, K, D]
tau (float): temperature during sampling, controlling uncertainty.</p>
<blockquote class="last">
<div>If tau &gt; 1: increase uncertainty
If tau &lt; 1: decrease uncertainty</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd>x (Tensor): sampled data, shape [N, D]</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.networks.BaseVAE">
<em class="property">class </em><code class="descclassname">lagom.core.networks.</code><code class="descname">BaseVAE</code><span class="sig-paren">(</span><em>config=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for variational autoencoders (VAE), works for both MLP and CNN versions.</p>
<p>Note that if subclass overrides __init__, remember to provide
keywords aguments, i.e. <a href="#id9"><span class="problematic" id="id10">**</span></a>kwargs passing to super().__init__.</p>
<p>All inherited subclasses should at least implement the following functions:
1. make_encoder(self, config)
2. make_moment_heads(self, config)
3. make_decoder(self, config)
4. init_params(self, config)
5. encoder_forward(self, x)
6. decoder_forward(self, x)</p>
<p>Examples:</p>
<dl class="docutils">
<dt>class VAE(BaseVAE):</dt>
<dd><dl class="first last docutils">
<dt>def make_encoder(self, config):</dt>
<dd><p class="first">fc1 = nn.Linear(in_features=16, out_features=8)
fc2 = nn.Linear(in_features=8, out_features=4)</p>
<p>encoder = nn.ModuleList([fc1, fc2])</p>
<p class="last">return encoder</p>
</dd>
<dt>def make_moment_heads(self, config):</dt>
<dd><p class="first">mu_head = nn.Linear(in_features=4, out_features=2)
logvar_head = nn.Linear(in_features=4, out_features=2)</p>
<p class="last">return mu_head, logvar_head</p>
</dd>
<dt>def make_decoder(self, config):</dt>
<dd><p class="first">fc1 = nn.Linear(in_features=2, out_features=4)
fc2 = nn.Linear(in_features=4, out_features=8)
fc3 = nn.Linear(in_features=8, out_features=16)</p>
<p>decoder = nn.ModuleList([fc1, fc2, fc3])</p>
<p class="last">return decoder</p>
</dd>
<dt>def init_params(self, config):</dt>
<dd><p class="first">gain = nn.init.calculate_gain(‘relu’)</p>
<dl class="docutils">
<dt>for module in self.encoder:</dt>
<dd>nn.init.orthogonal_(module.weight, gain=gain)
nn.init.constant_(module.bias, 0.0)</dd>
</dl>
<p>nn.init.orthogonal_(self.mu_head.weight, gain=gain)
nn.init.constant_(self.mu_head.bias, 0.0)
nn.init.orthogonal_(self.logvar_head.weight, gain=gain)
nn.init.constant_(self.logvar_head.bias, 0.0)</p>
<dl class="last docutils">
<dt>for module in self.decoder:</dt>
<dd>nn.init.orthogonal_(module.weight, gain=gain)
nn.init.constant_(module.bias, 0.0)</dd>
</dl>
</dd>
<dt>def encoder_forward(self, x):</dt>
<dd><dl class="first docutils">
<dt>for module in self.encoder:</dt>
<dd>x = F.relu(module(x))</dd>
</dl>
<p class="last">return x</p>
</dd>
<dt>def decoder_forward(self, x):</dt>
<dd><dl class="first docutils">
<dt>for module in self.decoder[:-1]:</dt>
<dd>x = F.relu(module(x))</dd>
</dl>
<p># Element-wise binary output
x = torch.sigmoid(self.decoder[-1](x))</p>
<p class="last">return x</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="lagom.core.networks.BaseVAE.calculate_loss">
<code class="descname">calculate_loss</code><span class="sig-paren">(</span><em>reconstructed_x</em>, <em>x</em>, <em>mu</em>, <em>logvar</em>, <em>reconstruction_loss_type='BCE'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.calculate_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.calculate_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the VAE loss function
VAE_loss = Reconstruction_loss + KL_loss
Note that the losses are summed over all elements and batch</p>
<p>For details, see <a class="reference external" href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a>
The KL loss is derived in Appendix B</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>reconstructed_x (Tensor): reconstructed x output from decoder
x (Tensor): ground-truth x
mu (Tensor): mean of the latent variable
logvar (Tensor): log-variance of the latent variable
loss_type (str): Type of reconstruction loss, supported [‘BCE’, ‘MSE’]</dd>
<dt>Returns:</dt>
<dd>loss (Tensor): VAE loss</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.decoder_forward">
<code class="descname">decoder_forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.decoder_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.decoder_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to define forward pass of decoder.</p>
<p>It should use the class member, self.decoder, 
which is a ModuleList consisting of all defined parameters (layers) for decoder.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (Tensor): the sampled latent variable according to output from moment heads</dd>
<dt>Returns:</dt>
<dd>x (Tensor): the reconstruction of the input</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.encoder_forward">
<code class="descname">encoder_forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.encoder_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.encoder_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to define forward pass of encoder.</p>
<p>It should use the class member, self.encoder, 
which is a ModuleList consisting of all defined parameters (layers) for encoder.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (Tensor): input tensor to encoder</dd>
<dt>Returns:</dt>
<dd>x (Tensor): features of encoder</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.make_decoder">
<code class="descname">make_decoder</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.make_decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.make_decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all the parameters (layers) for decoder</p>
<p>Note that it must return a ModuleList, otherwise they cannot be tracked by PyTorch.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Returns:</dt>
<dd>decoder (ModuleList): ModuleList of decoder.</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.make_encoder">
<code class="descname">make_encoder</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.make_encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.make_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all the parameters (layers) for encoder</p>
<p>Note that it must return a ModuleList, otherwise they cannot be tracked by PyTorch.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Returns:</dt>
<dd>encoder (ModuleList): ModuleList of encoder.</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.make_moment_heads">
<code class="descname">make_moment_heads</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.make_moment_heads"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.make_moment_heads" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all the parameters (layers) for heads of mu and logvar.</p>
<p>Note that it must return a ModuleList, otherwise they cannot be tracked by PyTorch.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Returns:</dt>
<dd>mu_head (nn.Module): A module for mu head
logvar_head (nn.Module): A module for logvar head</dd>
<dt>Examples:</dt>
<dd>TODO</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.make_params">
<code class="descname">make_params</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.make_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.make_params" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to create all trainable parameters (layers)</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>config (Config): configurations</dd>
<dt>Examples:</dt>
<dd>Refer to each inherited subclass with individual documentation.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.networks.BaseVAE.reparameterize">
<code class="descname">reparameterize</code><span class="sig-paren">(</span><em>mu</em>, <em>logvar</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/networks/base_vae.html#BaseVAE.reparameterize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.networks.BaseVAE.reparameterize" title="Permalink to this definition">¶</a></dt>
<dd><p>Sampling using reparameterization trick</p>
<p>i.e. mu + eps*std, eps sampled from N(0, 1)</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">mu (Tensor): mean of a Gaussian random variable
logvar (Tensor): log-variance of a Gaussian random variable</p>
<blockquote class="last">
<div>Note that log operation allows to optimize negative values,
though variance must be non-negative.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd>sampled tensor according to the reparameterization trick</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="plotter">
<h2>Plotter<a class="headerlink" href="#plotter" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lagom.core.plotter.BasePlot">
<em class="property">class </em><code class="descclassname">lagom.core.plotter.</code><code class="descname">BasePlot</code><a class="reference internal" href="_modules/lagom/core/plotter/base_plot.html#BasePlot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.BasePlot" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for plotting the experiment result.</p>
<p>Many modern research plots are done via Seaborn, exploiting DataFrame data structure
from Pandas.
e.g.
- loss curves with uncertainties from different random seeds. 
- Heatmaps with value shown in each cell. 
- Kernel Density Estimation (KDE) plots.</p>
<p>All inherited subclasses should at least implement the following functions:
1. __call__(self, <a href="#id11"><span class="problematic" id="id12">**</span></a>kwargs)</p>
<dl class="method">
<dt id="lagom.core.plotter.BasePlot.add">
<code class="descname">add</code><span class="sig-paren">(</span><em>name</em>, <em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/plotter/base_plot.html#BasePlot.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.BasePlot.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a new data for plotting.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>name (str): name of the given data
data (object): given data</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.plotter.CurvePlot">
<em class="property">class </em><code class="descclassname">lagom.core.plotter.</code><code class="descname">CurvePlot</code><a class="reference internal" href="_modules/lagom/core/plotter/curve_plot.html#CurvePlot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.CurvePlot" title="Permalink to this definition">¶</a></dt>
<dd><p>Compare different curves in one plot. In machine learning research, it is 
extremely useful, e.g. compare training losses with different baselines.</p>
<p>Note that the uncertainty (error bands) is supported, a standard use case
is that each baseline run several times by using different random seeds.</p>
<p>Either with or without uncertainty, it depends on what kind of data added
to the plotter via <cite>add(name, data)</cite>. If the data is one-dimentional, it will
be treated as a single curve. If the data is two-dimensional, it will be plotted
with uncertainty.</p>
<p>To generate a modern high quality research plot, we use Seaborn.lineplot with 
Pandas.DataFrame data structure.</p>
<p>For more advanced use cases, feel free to inherit this class and overide <cite>__call__</cite>.</p>
<dl class="method">
<dt id="lagom.core.plotter.CurvePlot.add">
<code class="descname">add</code><span class="sig-paren">(</span><em>name</em>, <em>data</em>, <em>xvalues=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/plotter/curve_plot.html#CurvePlot.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.CurvePlot.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a curve data (either one of multiple) with option to select range of values
for horizontal axis. If not provided, then it will be automatically set to integers.</p>
<p>Note that only one list of xvalues needed, because all curve data should share identical
horizontal axis. If a batch of xvalues are provided and they are not identical, 
then each line will be interpolated and new shared xvalues and queried y values will be computed.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>name (str): name of the curve
data (list/ndarray): curve data. If multiple curves (list) provided, then it will plot uncertainty bands. 
xvalues (list, optional): values for horizontal axis. If None, then it set to be integers.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lagom.core.plotter.CurvePlot.tick_formatter">
<code class="descname">tick_formatter</code><span class="sig-paren">(</span><em>x</em>, <em>pos</em>, <em>scale_magnitude=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/plotter/curve_plot.html#CurvePlot.tick_formatter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.CurvePlot.tick_formatter" title="Permalink to this definition">¶</a></dt>
<dd><p>A function to set major functional formatter.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">x (object): data value, internal argument used by Matplotlib
pos (object): position, internal argument used by Matplotlib
scale_magnitude (str): string description of scaling magnitude, use functools.partial</p>
<blockquote class="last">
<div><p>to make a function specified with this scaler but without put it as a required argument. 
Possible values:</p>
<blockquote>
<div><ul class="simple">
<li>‘N’: no scaling, raw value</li>
<li>‘K’: every one thousand</li>
<li>‘M’: every one million</li>
</ul>
</div></blockquote>
<p>When None is given, then it automatically detect for N, K or M.</p>
</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd>A formatted string of the tick given the data value.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.plotter.GridImage">
<em class="property">class </em><code class="descclassname">lagom.core.plotter.</code><code class="descname">GridImage</code><span class="sig-paren">(</span><em>ncol=8</em>, <em>padding=2</em>, <em>pad_value=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/plotter/grid_image.html#GridImage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.GridImage" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a grid of images. The images can be iteratively added.</p>
<p>Examples:</p>
<blockquote>
<div><p>grid = GridImage(ncol=8, padding=5, pad_value=0)</p>
<p>a = np.random.randint(0, 255+1, size=[10, 3, 64, 64])
grid.add(a)
grid()</p>
</div></blockquote>
<dl class="docutils">
<dt>Reference: </dt>
<dd><a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/utils.py">https://github.com/pytorch/vision/blob/master/torchvision/utils.py</a>
<a class="reference external" href="https://github.com/facebookresearch/visdom/blob/master/py/visdom/__init__.py">https://github.com/facebookresearch/visdom/blob/master/py/visdom/__init__.py</a></dd>
</dl>
<dl class="method">
<dt id="lagom.core.plotter.GridImage.add">
<code class="descname">add</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/plotter/grid_image.html#GridImage.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.plotter.GridImage.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Add new data for making grid images.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (list/ndarray): a list or ndarray of images, with shape either [H, W], [C, H, W] or [N, C, H, W]</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="policies">
<h2>Policies<a class="headerlink" href="#policies" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lagom.core.policies.BasePolicy">
<em class="property">class </em><code class="descclassname">lagom.core.policies.</code><code class="descname">BasePolicy</code><span class="sig-paren">(</span><em>network</em>, <em>env_spec</em>, <em>config</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/policies/base_policy.html#BasePolicy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.policies.BasePolicy" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for the policy.</p>
<p>It receives user-defined network (must be of types in lagom.core.networks),
environment specification (of type EnvSpec) and configuration.</p>
<p>All inherited subclasses should at least implement the following functions
1. __call__(self, x)
2. process_network_output(self, network_out)</p>
<dl class="method">
<dt id="lagom.core.policies.BasePolicy.process_network_output">
<code class="descname">process_network_output</code><span class="sig-paren">(</span><em>network_out</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/policies/base_policy.html#BasePolicy.process_network_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.policies.BasePolicy.process_network_output" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to support additional processing of the 
output from the internal network.</p>
<p>It can also return a processed output. If there is nothing to do, 
then return it back, i.e. return network_out</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>network_out (dict): Dictionary of data returned from forward pass of internal network.</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>processed_network_out (dict): A dictionary of processed network output. </dt>
<dd>It will be returned together in __call__. Default to return back
of network_out</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.policies.RandomPolicy">
<em class="property">class </em><code class="descclassname">lagom.core.policies.</code><code class="descname">RandomPolicy</code><span class="sig-paren">(</span><em>network</em>, <em>env_spec</em>, <em>config</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/policies/random_policy.html#RandomPolicy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.policies.RandomPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p>A random policy. The action is sampled from action space.</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.policies.BaseCategoricalPolicy">
<em class="property">class </em><code class="descclassname">lagom.core.policies.</code><code class="descname">BaseCategoricalPolicy</code><span class="sig-paren">(</span><em>network</em>, <em>env_spec</em>, <em>config</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/policies/base_categorical_policy.html#BaseCategoricalPolicy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.policies.BaseCategoricalPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class of categorical policy for discrete action space. 
Action can be sampled from a categorical distribution.</p>
<p>Note that the user-defined network should return a dictionary
from its forward function. At least with the key [‘action_scores’] (without softmax). 
It can also contain the key ‘value’ for the value function of actor-critic network.</p>
<p>All inherited subclasses should at least implement the following function
1. process_network_output(self, network_out)</p>
<p>Examples:</p>
<blockquote>
<div><p>env = gym.make(‘CartPole-v0’)
env_spec = EnvSpec(GymEnv(env))</p>
<dl class="docutils">
<dt>class MLP(BaseMLP):</dt>
<dd><dl class="first last docutils">
<dt>def make_params(self, config):</dt>
<dd>self.fc1 = nn.Linear(in_features=4, out_features=32)
self.fc2 = nn.Linear(in_features=32, out_features=2)</dd>
<dt>def init_params(self, config):</dt>
<dd><p class="first">gain = nn.init.calculate_gain(nonlinearity=’relu’)</p>
<p>nn.init.orthogonal_(self.fc1.weight, gain=gain)
nn.init.constant_(self.fc1.bias, 0.0)</p>
<p class="last">nn.init.orthogonal_(self.fc2.weight, gain=gain)
nn.init.constant_(self.fc2.bias, 0.0)</p>
</dd>
<dt>def forward(self, x):</dt>
<dd><p class="first">x = F.relu(self.fc1(x))
x = self.fc2(x)</p>
<p># Output dictionary
out = {}
out[‘action_scores’] = x</p>
<p class="last">return out</p>
</dd>
</dl>
</dd>
<dt>class CategoricalPolicy(BaseCategoricalPolicy):</dt>
<dd><dl class="first last docutils">
<dt>def process_network_output(self, network_out):</dt>
<dd>return {}</dd>
</dl>
</dd>
</dl>
<p>network = MLP(config=None)
policy = CategoricalPolicy(network=network, env_spec=env_spec)</p>
</div></blockquote>
</dd></dl>

<dl class="class">
<dt id="lagom.core.policies.BaseGaussianPolicy">
<em class="property">class </em><code class="descclassname">lagom.core.policies.</code><code class="descname">BaseGaussianPolicy</code><span class="sig-paren">(</span><em>network</em>, <em>env_spec</em>, <em>config</em>, <em>min_std=1e-06</em>, <em>std_style='exp'</em>, <em>constant_std=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/policies/base_gaussian_policy.html#BaseGaussianPolicy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.policies.BaseGaussianPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class of Gaussian policy (independent) for continuous action space. 
Action can be sampled from a Normal distribution.</p>
<p>Note that the user-defined network should return a dictionary
from its forward function. At least with the key [‘mean’, ‘logvar’]. 
It can also contain the key ‘value’ for the value function of actor-critic network.</p>
<dl class="docutils">
<dt>Depending on the cases, the standard deviation can be state-dependent or state-independent.</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>state-dependent: the std trainable parameters are connected from the last output layer.</dt>
<dd>e.g. logvar_head = nn.Linear(in_features=64, out_features=4)</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>state-independent: the std trainable parameters are exclusive from policy network parameters. </dt>
<dd>e.g. logvar_head = nn.Parameter(torch.full([4], -4.6))  # -4.6 = log(0.1**2) for 0.1 as init std</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<p>Sometimes, it can also be useful to have constant standard deviation, it is supported with this class.</p>
<p>All inherited subclasses should at least implement the following function
1. process_network_output(self, network_out)
2. constraint_action(self, action)</p>
<p>Examples:</p>
<blockquote>
<div><p>env = gym.make(‘Pendulum-v0’)
env_spec = EnvSpec(GymEnv(env))</p>
<dl class="docutils">
<dt>class MLP(BaseMLP):</dt>
<dd><dl class="first last docutils">
<dt>def make_params(self, config):</dt>
<dd><p class="first">self.fc1 = nn.Linear(in_features=3, out_features=32)</p>
<p class="last">self.mean_head = nn.Linear(in_features=32, out_features=1)
self.logvar_head = nn.Linear(in_features=32, out_features=1)</p>
</dd>
<dt>def init_params(self, config):</dt>
<dd><p class="first">gain = nn.init.calculate_gain(nonlinearity=’relu’)</p>
<p>nn.init.orthogonal_(self.fc1.weight, gain=gain)
nn.init.constant_(self.fc1.bias, 0.0)</p>
<p>nn.init.orthogonal_(self.mean_head.weight, gain=gain)
nn.init.constant_(self.mean_head.bias, 0.0)</p>
<p class="last">nn.init.orthogonal_(self.logvar_head.weight, gain=gain)
nn.init.constant_(self.logvar_head.bias, 0.0)</p>
</dd>
<dt>def forward(self, x):</dt>
<dd><p class="first">x = F.relu(self.fc1(x))</p>
<p>mean = self.mean_head(x)
logvar = self.logvar_head(x)</p>
<p># Output dictionary
out = {}
out[‘mean’] = mean
out[‘logvar’] = logvar</p>
<p class="last">return out</p>
</dd>
</dl>
</dd>
<dt>class GaussianPolicy(BaseGaussianPolicy):</dt>
<dd><dl class="first last docutils">
<dt>def process_network_output(self, network_out):</dt>
<dd>return {}</dd>
<dt>def constraint_action(self, action):</dt>
<dd>return 2*torch.tanh(action)</dd>
</dl>
</dd>
</dl>
<p>network = MLP(config=None)
policy = GaussianPolicy(network=network, env_spec=env_spec)</p>
</div></blockquote>
<dl class="method">
<dt id="lagom.core.policies.BaseGaussianPolicy.constraint_action">
<code class="descname">constraint_action</code><span class="sig-paren">(</span><em>action</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/policies/base_gaussian_policy.html#BaseGaussianPolicy.constraint_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.policies.BaseGaussianPolicy.constraint_action" title="Permalink to this definition">¶</a></dt>
<dd><p>User-defined function to smoothly constraint the action with upper/lower bounds.</p>
<p>The constraint must be smooth (differentiable), it is recommended to use functions
like tanh, or sigmoid. For example the action is in the range of [-2, 2], one can define
<cite>constrained_action = 2*torch.tanh(action)</cite>.</p>
<p>If there is no need to constraint, then it is required to send the action back. 
i.e. <cite>return action</cite></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>action (Tensor): action sampled from Normal distribution.</dd>
<dt>Returns:</dt>
<dd>constrained_action (Tensor): constrained action.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="transformations">
<h2>Transformations<a class="headerlink" href="#transformations" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lagom.core.transform.BaseTransform">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">BaseTransform</code><a class="reference internal" href="_modules/lagom/core/transform/base_transform.html#BaseTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.BaseTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for transforms, clipping, normalize, centralize, standardize etc.</p>
<p>Note that all inherited class should support only scalar value or 1-dim vector. 
Because it has much higher risk to introduce bugs with larger dimensionality.</p>
<p>It is recommended to convert all numpy processed data to type, np.float32
becuase it is more compatible with PyTorch. Numpy default float64 often 
can lead to numerical issues or raised exceptions in PyTorch. Similarly
for np.int32.</p>
<p>All inherited subclasses should at least implement the following functions:
1. __call__(self, x)</p>
<dl class="method">
<dt id="lagom.core.transform.BaseTransform.make_input">
<code class="descname">make_input</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/transform/base_transform.html#BaseTransform.make_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.BaseTransform.make_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Conver the input as scalar or 1-dim ndarray</p>
<ol class="arabic simple">
<li>scalar: retain the same</li>
<li>list: convert to 1-dim ndarray with shape [D]</li>
</ol>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (scalar/list/ndarray): input data</dd>
<dt>Returns:</dt>
<dd>x (ndarray): converted data</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.Centralize">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">Centralize</code><a class="reference internal" href="_modules/lagom/core/transform/centralize.html#Centralize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.Centralize" title="Permalink to this definition">¶</a></dt>
<dd><p>Centralize the input data: Subtracted by mean.</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.Normalize">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">Normalize</code><span class="sig-paren">(</span><em>eps=1.1920929e-07</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/transform/normalize.html#Normalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.Normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize the input data: Subtracted by minimal and divided by range (maximal - minimal)</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.Standardize">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">Standardize</code><span class="sig-paren">(</span><em>eps=1.1920929e-07</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/transform/standardize.html#Standardize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.Standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Standardize the input data: Subtracted by mean and divided by standard deviation</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.Clip">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">Clip</code><a class="reference internal" href="_modules/lagom/core/transform/clip.html#Clip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.Clip" title="Permalink to this definition">¶</a></dt>
<dd><p>Clip the input data</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.ExpFactorCumSum">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">ExpFactorCumSum</code><span class="sig-paren">(</span><em>alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/transform/exp_factor_cumsum.html#ExpFactorCumSum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.ExpFactorCumSum" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate future accumulated sums with exponential factor.</p>
<p>e.g. Given input [x_1, …, x_n] and factor lpha, the computation returns an array y with same length
and y_i = x_i + lpha*x_{i+1} + lpha^2*x_{i+2} + … + lpha^{n-i-1}*x_{n-1} + lpha^{n-i}*x_{n}</p>
<p>Commonly useful for calculating returns in RL.</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.PolySmooth">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">PolySmooth</code><a class="reference internal" href="_modules/lagom/core/transform/polysmooth.html#PolySmooth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.PolySmooth" title="Permalink to this definition">¶</a></dt>
<dd><p>Use least squares polynomial fit to smooth the curve.</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.RankTransform">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">RankTransform</code><a class="reference internal" href="_modules/lagom/core/transform/rank_transform.html#RankTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.RankTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Rank transformation of the input vector. The rank has the same dimensionality as input vector.
Each element in the rank indicates the index of the ascendingly sorted input.
i.e. ranks[i] = k, it means i-th element in the input is k-th smallest value.</p>
<p>Rank transformation reduce sensitivity to outliers, e.g. in OpenAI ES, gradient computation
involves fitness values in the population, if there are outliers (too large fitness), it affects
the gradient too much.</p>
<p>Note that a centered rank transformation to the range [-0.5, 0.5] is supported by an option.</p>
</dd></dl>

<dl class="class">
<dt id="lagom.core.transform.RunningMeanStd">
<em class="property">class </em><code class="descclassname">lagom.core.transform.</code><code class="descname">RunningMeanStd</code><span class="sig-paren">(</span><em>dtype='list'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/transform/running_mean_std.html#RunningMeanStd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.RunningMeanStd" title="Permalink to this definition">¶</a></dt>
<dd><p>Online algorithm for estimating sample mean and standard deviation</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm">https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm</a></p>
<dl class="method">
<dt id="lagom.core.transform.RunningMeanStd.make_input">
<code class="descname">make_input</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lagom/core/transform/running_mean_std.html#RunningMeanStd.make_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lagom.core.transform.RunningMeanStd.make_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Conver the input as scalar or 1-dim ndarray</p>
<ol class="arabic simple">
<li>scalar: retain the same</li>
<li>list: convert to 1-dim ndarray with shape [D]</li>
</ol>
<dl class="docutils">
<dt>Args:</dt>
<dd>x (scalar/list/ndarray): input data</dd>
<dt>Returns:</dt>
<dd>x (ndarray): converted data</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.transform.RunningMeanStd.mu">
<code class="descname">mu</code><a class="headerlink" href="#lagom.core.transform.RunningMeanStd.mu" title="Permalink to this definition">¶</a></dt>
<dd><p>Running mean</p>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.transform.RunningMeanStd.n">
<code class="descname">n</code><a class="headerlink" href="#lagom.core.transform.RunningMeanStd.n" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples</p>
</dd></dl>

<dl class="attribute">
<dt id="lagom.core.transform.RunningMeanStd.sigma">
<code class="descname">sigma</code><a class="headerlink" href="#lagom.core.transform.RunningMeanStd.sigma" title="Permalink to this definition">¶</a></dt>
<dd><p>Running standard deviation</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="utils">
<h2>Utils<a class="headerlink" href="#utils" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="engine.html" class="btn btn-neutral float-right" title="lagom.engine" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="contrib.html" class="btn btn-neutral" title="lagom.contrib" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Xingdong Zuo.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>